<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>å®¶ç”¨ä¼ºæœå™¨æŠ˜è…¾æ‰‹è®°-3ï¼šMac mini éƒ¨ç½² Open WebUI æ•™ç¨‹ - Moreyu's Blog</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/maple-mono@latest/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script><style>body{font-family:"Maple Mono",monospace;line-height:1.6;max-width:800px;margin:0 auto;padding:20px;background:#f5f5f7;color:#333}pre{background:#1e1e1e;padding:15px;border-radius:8px;overflow-x:auto}code{font-family:"Maple Mono",monospace}h1,h2,h3{color:#FF375F}a{color:#0066cc;text-decoration:none}a:hover{text-decoration:underline}.meta{color:#666;font-size:.9em;margin-bottom:30px}img{max-width:100%;border-radius:8px;margin:20px 0}@media (prefers-color-scheme:dark){body{background:#000;color:#f5f5f7}a{color:#2997ff}h1,h2,h3{color:#FF453A}}.back-to-home{position:fixed;bottom:20px;right:20px;background:rgba(255,55,95,.9);color:white;padding:10px 20px;border-radius:20px;backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);box-shadow:0 4px 6px rgba(0,0,0,.1);transition:all .3s ease}.back-to-home:hover{transform:translateY(-2px);box-shadow:0 6px 8px rgba(0,0,0,.2);text-decoration:none}.tip{background:rgba(255,55,95,.1);padding:15px;border-radius:8px;margin:20px 0;border-left:4px solid #FF375F}@media (max-width:768px){body{padding:15px}pre{padding:10px;font-size:14px}.back-to-home{bottom:15px;right:15px;padding:8px 16px}}</style></head><body><h1>å®¶ç”¨ä¼ºæœå™¨æŠ˜è…¾æ‰‹è®°-3ï¼šMac mini éƒ¨ç½² Open WebUI æ•™ç¨‹ ğŸ¤–</h1><div class="meta">å‘å¸ƒæ—¶é—´ï¼š2025-03-09 | åˆ†ç±»ï¼šæœåŠ¡å™¨, Docker, AI</div><h2>å‰è¨€ ğŸ“</h2><p>åœ¨å‰ä¸¤ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»æ­å»ºäº†åŸºç¡€çš„ Docker ç¯å¢ƒå¹¶éƒ¨ç½²äº†ä¸€äº›å®ç”¨æœåŠ¡ã€‚è¿™æ¬¡æˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•åœ¨ Mac mini ä¸Šéƒ¨ç½² Open WebUIï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æº AI æ¨¡å‹ç®¡ç†å’Œä½¿ç”¨ç•Œé¢ï¼Œæ”¯æŒè¿è¡Œå„ç§å¤§è¯­è¨€æ¨¡å‹ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿåœ¨æœ¬åœ°æ­å»ºå±äºè‡ªå·±çš„ AI åŠ©æ‰‹ã€‚</p><h2>å‡†å¤‡å·¥ä½œ ğŸ› ï¸</h2><div class="tip"><strong>æç¤ºï¼š</strong>ç¡®ä¿ä½ çš„ Mac mini æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼ˆå»ºè®® 16GB ä»¥ä¸Šï¼‰å’Œå­˜å‚¨ç©ºé—´ï¼ˆå»ºè®® 256GB ä»¥ä¸Šï¼‰ã€‚</div><h3>1. åˆ›å»ºå·¥ä½œç›®å½•</h3><pre><code class="bash">mkdir -p ~/docker/open-webui
cd ~/docker/open-webui</code></pre><h3>2. åˆ›å»ºé…ç½®æ–‡ä»¶</h3><pre><code class="yaml"># docker-compose.yml
version: '3'
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_API_HOST=http://ollama:11434
      - WEBUI_SECRET_KEY=your-secret-key
    volumes:
      - ./data:/data
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama</code></pre><h2>éƒ¨ç½²æ­¥éª¤ ğŸš€</h2><h3>1. å¯åŠ¨æœåŠ¡</h3><pre><code class="bash">docker-compose up -d</code></pre><h3>2. æ£€æŸ¥æœåŠ¡çŠ¶æ€</h3><pre><code class="bash">docker ps | grep webui
docker logs -f open-webui</code></pre><h2>åŸºç¡€é…ç½® âš™ï¸</h2><h3>1. è®¿é—® Web ç•Œé¢</h3><p>æ‰“å¼€æµè§ˆå™¨è®¿é—® <code>http://localhost:8080</code>ï¼Œé¦–æ¬¡è®¿é—®éœ€è¦è®¾ç½®ç®¡ç†å‘˜è´¦å·å’Œå¯†ç ã€‚</p><h3>2. ä¸‹è½½æ¨¡å‹</h3><pre><code class="bash"># åœ¨ç»ˆç«¯ä¸­ä¸‹è½½æ¨¡å‹
docker exec -it ollama pull llama2
docker exec -it ollama pull mistral
docker exec -it ollama pull codellama</code></pre><h2>è¿›é˜¶é…ç½® ğŸ”§</h2><h3>1. è‡ªå®šä¹‰æ¨¡å‹é…ç½®</h3><pre><code class="yaml"># modelfile
FROM llama2

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 50

SYSTEM You are a helpful AI assistant.</code></pre><h2>æ€§èƒ½ä¼˜åŒ– ğŸš„</h2><h3>1. æ˜¾å­˜ç®¡ç†</h3><pre><code class="yaml"># åœ¨ docker-compose.yml ä¸­æ·»åŠ æ˜¾å­˜é™åˆ¶
services:
  ollama:
    environment:
      - CUDA_MEMORY_LIMIT=8G</code></pre><h3>2. æ¨¡å‹é‡åŒ–</h3><pre><code class="bash"># ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬çš„æ¨¡å‹ä»¥å‡å°‘å†…å­˜å ç”¨
docker exec -it ollama pull llama2:7b-q4</code></pre><h2>å¸¸è§é—®é¢˜ ğŸ’¡</h2><h3>1. å†…å­˜ç®¡ç†</h3><ul><li>ä½¿ç”¨é‡åŒ–æ¨¡å‹å‡å°‘å†…å­˜å ç”¨</li><li>åŠæ—¶æ¸…ç†æœªä½¿ç”¨çš„æ¨¡å‹</li><li>ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ</li></ul><h3>2. API è®¿é—®é—®é¢˜</h3><ul><li>æ£€æŸ¥ç«¯å£é…ç½®</li><li>ç¡®è®¤é˜²ç«å¢™è®¾ç½®</li><li>éªŒè¯ API å¯†é’¥é…ç½®</li></ul><h2>åç»­è®¡åˆ’ ğŸ“ˆ</h2><p>åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ï¼š</p><ul><li>å¦‚ä½•ä½¿ç”¨ FastAPI æ„å»º AI æœåŠ¡ API</li><li>å¦‚ä½•å®ç°æ¨¡å‹çƒ­åŠ è½½å’ŒåŠ¨æ€åˆ‡æ¢</li><li>å¦‚ä½•ä¼˜åŒ–å¤§è§„æ¨¡å¹¶å‘è¯·æ±‚å¤„ç†</li><li>å¦‚ä½•é›†æˆå‘é‡æ•°æ®åº“å®ç°çŸ¥è¯†åº“é—®ç­”</li></ul><a href="/" class="back-to-home">è¿”å›é¦–é¡µ ğŸ </a><script>hljs.highlightAll();</script></body></html>
